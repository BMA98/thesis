{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn6cAQrqklxt"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "Due to this codebase being inherited from 2022, we have to install a previous version of torch due to torchtext being deprecated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE1GqeI3BjeY",
        "outputId": "db0560a6-fefa-4a39-e493-95bb991f4c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 triton-2.3.0\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18.0) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n",
            "Collecting torchvision==0.18.0\n",
            "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision==0.18.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision==0.18.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision==0.18.0) (1.3.0)\n",
            "Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Successfully installed torchvision-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch==2.3.0\n",
        "!pip install --upgrade torchtext==0.18.0\n",
        "!pip install --upgrade torchvision==0.18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXOekFr-5tui"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Vaw61kkGED"
      },
      "source": [
        "## Shared codebase\n",
        "\n",
        "The following defines useful methods, the definition of models to use and anything that is not subject to change.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVaOnlthn3F1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19af78f5-267b-49a0-8e8f-aea13a22071c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab as torch_vocab\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def build_vocab_from_corpus(dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Given a corpus, builds a Vocab object with tokenizer function.\n",
        "    \"\"\"\n",
        "    counter = Counter()\n",
        "    for _headline, _body, _ in dataset:\n",
        "        counter.update(tokenizer(_headline + \"\\n\\n\" + _body))\n",
        "    v = torch_vocab(counter, specials=[\"BOH\", \"EOH\", \"BOP\", \"EOP\"])\n",
        "    return v\n",
        "\n",
        "def calculate_metrics(predictions, y_true):\n",
        "    \"\"\"\n",
        "    A simple funcion that given predictions and the expected results\n",
        "    will return the precision, recall and f1 (macro).\n",
        "    \"\"\"\n",
        "    y_pred = predictions.argmax(dim=1)\n",
        "    y_true = y_true.argmax(dim=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    return precision, recall, f1\n",
        "\n",
        "def training_step(model, dataloader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Given a model, a dataloader, a optimizer and a criterion, it wil perform\n",
        "    a training step in batches.\n",
        "    \"\"\"\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    for labels, headlines, bodies in dataloader:\n",
        "        i += 1\n",
        "        # Move to device (usually GPU/TPU)\n",
        "        labels = labels.to(device)\n",
        "        headlines = headlines.to(device)\n",
        "        bodies = bodies.to(device)\n",
        "        # Reset gradients for previous steps\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform predictions\n",
        "        predictions = model(headlines, bodies)\n",
        "\n",
        "        # Criterion to define target\n",
        "        loss = criterion(predictions, torch.argmax(labels, dim=1))\n",
        "\n",
        "        # Metrics\n",
        "        predictions = predictions.to('cpu')\n",
        "        labels = labels.to('cpu')\n",
        "        headlines = headlines.to('cpu')\n",
        "        bodies = bodies.to('cpu')\n",
        "        precision, recall, f1 = calculate_metrics(predictions, labels)\n",
        "\n",
        "        # Gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimization\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_precision / len(\n",
        "        dataloader), epoch_recall / len(dataloader), epoch_f1 / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for labels, headlines, bodies in dataloader:\n",
        "\n",
        "            labels = labels.to(device)\n",
        "            headlines = headlines.to(device)\n",
        "            bodies = bodies.to(device)\n",
        "\n",
        "            # Predecimos\n",
        "            predictions = model(headlines, bodies)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, torch.argmax(labels, dim=1))\n",
        "\n",
        "            predictions = predictions.to('cpu')\n",
        "            labels = labels.to('cpu')\n",
        "            headlines = headlines.to('cpu')\n",
        "            bodies = bodies.to('cpu')\n",
        "\n",
        "            # Calculamos las métricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, labels)\n",
        "\n",
        "            # Actualizamos el loss y las métricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_precision / len(\n",
        "        dataloader), epoch_recall / len(dataloader), epoch_f1 / len(dataloader)\n",
        "\n",
        "\n",
        "def run_experiment(model, model_name, criterion, train_dataloader, valid_dataloader, n_epochs, device):\n",
        "\n",
        "  model.to(device)\n",
        "  criterion.to(device)\n",
        "  best_valid_loss = float('inf')\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "      start_time = time.time()\n",
        "\n",
        "      # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "      # Entrenar\n",
        "      train_loss, train_precision, train_recall, train_f1 = training_step(\n",
        "            model, train_dataloader, optimizer, criterion, device)\n",
        "\n",
        "      print(\"Finishing training epoch\")\n",
        "\n",
        "        # Evaluar (valid = validación)\n",
        "      valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "            model, valid_dataloader, criterion)\n",
        "\n",
        "        #print(\"Finishing validation epoch\")\n",
        "      end_time = time.time()\n",
        "\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "        # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
        "      if valid_loss < best_valid_loss:\n",
        "          best_valid_loss = valid_loss\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/Tesis/{}.pt'.format(model_name))\n",
        "        # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
        "\n",
        "      print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "      print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "class FakeNewsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for Clickbait Webis 20217 Dataset.\n",
        "    Assumes data has already been preprocessed and has a format\n",
        "    (headline, body, truthClass).\n",
        "    \"\"\"\n",
        "    def __init__(self, path='data/clickbait', split='train'):\n",
        "        if split not in ['train', 'test', 'valid']:\n",
        "            raise ValueError(f'Dataset {split} not found, it must be train, valid or test')\n",
        "        self.split = split\n",
        "        dataset = pd.read_csv(f'{path}/{split}.csv')\n",
        "        self.headlines = list(dataset['headline'])\n",
        "        self.bodies = list(dataset['body'])\n",
        "        self.labels = list(dataset['label'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.headlines[idx], self.bodies[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "class ClickbaitDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for Clickbait Webis 20217 Dataset.\n",
        "    Assumes data has already been preprocessed and has a format\n",
        "    (headline, body, truthClass).\n",
        "    \"\"\"\n",
        "    def __init__(self, path='data/clickbait', split='train'):\n",
        "        if split not in ['train', 'test', 'valid']:\n",
        "            raise ValueError(f'Dataset {split} not found, it must be train, valid or test')\n",
        "        self.split = split\n",
        "        if split == 'valid':\n",
        "            split = 'validation'\n",
        "        dataset = pd.read_csv(f'{path}/{split}/{split}.csv')\n",
        "        self.headlines = list(dataset['headline'])\n",
        "        self.bodies = list(dataset['body'])\n",
        "        self.labels = list(dataset['truthClass'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.headlines[idx], self.bodies[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "class IncongruenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for FNC-1 Dataset.\n",
        "    Assumes data has already been preprocessed and\n",
        "    has a format (headline, body, labels)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path='../data/fnc-1', split='train'):\n",
        "        if split not in ['train', 'test', 'valid']:\n",
        "            raise ValueError(f'Dataset {split} not found, it must be train, valid or test')\n",
        "        self.split= split\n",
        "        dataset = pd.read_csv(f'{path}/{split}.csv')\n",
        "        self.headlines = list(dataset['headline'])\n",
        "        self.bodies = list(dataset['body'])\n",
        "        self.labels = list(dataset['label'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.headlines[idx], self.bodies[idx], self.labels[idx])\n",
        "\n",
        "\n",
        "class BiDualEncoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self, vocab_size,\n",
        "            vectors=None,\n",
        "            embed_dim=300,\n",
        "            hidden_dim=128,\n",
        "            hidden_layers=2,\n",
        "            output_dim=2,\n",
        "            freeze_embed=True,\n",
        "            dropout=0.3,\n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Shared embedding layer\n",
        "        if vectors is not None:\n",
        "          self.embedding_layer = nn.Embedding(vocab_size, embed_dim).from_pretrained(\n",
        "              vectors,\n",
        "              freeze=freeze_embed\n",
        "          )\n",
        "        else:\n",
        "          self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "\n",
        "        # Encoders\n",
        "        self.headline_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=hidden_layers, bidirectional=True)\n",
        "        self.body_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=hidden_layers, bidirectional=True)\n",
        "\n",
        "        # Prediction\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, headline, body):\n",
        "\n",
        "        # Representations\n",
        "        headline_embedding = self.embedding_layer(headline)\n",
        "        body_embedding = self.embedding_layer(body)\n",
        "\n",
        "\n",
        "        # Headline latent representation\n",
        "        headline_lstm, _ = self.headline_lstm(headline_embedding)\n",
        "\n",
        "        # Body latent representation\n",
        "        body_lstm, _ = self.body_lstm(body_embedding)\n",
        "\n",
        "        # Average latest output (bidirectional)\n",
        "        # This is performerd taking the last\n",
        "        output_lstm = (headline_lstm[-1,:,:self.hidden_dim] + body_lstm[-1,:,:self.hidden_dim]) / 2\n",
        "        output = self.fc(self.dropout(output_lstm))\n",
        "        return output\n",
        "\n",
        "\n",
        "class BiConditionalDualEncoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self, vocab_size,\n",
        "            vectors=None,\n",
        "            embed_dim=300,\n",
        "            hidden_dim=128,\n",
        "            hidden_layers=2,\n",
        "            output_dim=2,\n",
        "            freeze_embed=True,\n",
        "            dropout=0.3,\n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Shared embedding layer\n",
        "        if vectors is not None:\n",
        "          self.embedding_layer = nn.Embedding(vocab_size, embed_dim).from_pretrained(\n",
        "              vectors,\n",
        "              freeze=freeze_embed\n",
        "          )\n",
        "        else:\n",
        "          self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "\n",
        "        # Encoders\n",
        "        self.headline_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=hidden_layers, bidirectional=True, dropout=dropout)\n",
        "        self.body_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=hidden_layers, bidirectional=True, dropout=dropout)\n",
        "\n",
        "        # Prediction\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, headline, body):\n",
        "\n",
        "        # Representations\n",
        "        headline_embedding = self.embedding_layer(headline)\n",
        "        body_embedding = self.embedding_layer(body)\n",
        "\n",
        "        # Headline latent representation\n",
        "        _, (h_hidden, h_cell) = self.headline_lstm(headline_embedding)\n",
        "\n",
        "        # Body latent representation\n",
        "        body_lstm, _ = self.body_lstm(body_embedding, (h_hidden, h_cell))\n",
        "\n",
        "        # Average outputs of body\n",
        "        output_lstm = (body_lstm[-1,:,:self.hidden_dim] + body_lstm[-1,:,self.hidden_dim:]) / 2\n",
        "        output = self.fc(self.dropout(output_lstm))\n",
        "        return output\n",
        "\n",
        "\n",
        "class LTSM_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers, padding_idx, vectors, bidirectional=False, dropout=0.3):\n",
        "        super().__init__()\n",
        "        # Embedding layer\n",
        "        self.embed_layer = nn.Embedding(input_dim, embedding_dim).from_pretrained(vectors, freeze=True)\n",
        "        # LSTM layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_headline = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.lstm_body = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_dim * 4 if bidirectional else hidden_dim * 2, output_dim)\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, headline, body):\n",
        "        # Embed text\n",
        "        headline_embed = self.embed_layer(headline)\n",
        "        body_embed = self.embed_layer(body)\n",
        "        # LSTM layer\n",
        "        outputs_heads, (hidden_heads, cell_heads) = self.lstm_headline(headline_embed)\n",
        "        outputs_bodies, (hidden_bodies, cell_bodies) = self.lstm_body(body_embed)\n",
        "        outputs_heads = outputs_heads[-1]\n",
        "        outputs_bodies = outputs_bodies[-1]\n",
        "        outputs = torch.cat((outputs_heads, outputs_bodies), 1)\n",
        "        # Make predictions\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRYjFRzYlN0Y"
      },
      "source": [
        "## Tokenization and collation\n",
        "\n",
        "While ideally this code is subject to little changes, we prefer to separate it from the shared and static codebase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trws11am_BL_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "vocab_transform = lambda x: [vocab[token] if token in vocab else 0 for token in tokenizer(x)]\n",
        "\n",
        "tensor_transform = lambda x: torch.tensor(x)\n",
        "\n",
        "def label_transform(label):\n",
        "    if label == 'true':\n",
        "        return [1, 0]\n",
        "    elif label == 'fake':\n",
        "        return [0, 1]\n",
        "\n",
        "def collate_batch(batch):\n",
        "    articles, headlines, labels = [], [], []\n",
        "    for (_headline, _body, _label) in batch:\n",
        "        # Transform the headline\n",
        "        _headline = tensor_transform(vocab_transform(_headline))\n",
        "        _body = tensor_transform(vocab_transform(_body)[:300])\n",
        "        headlines.append(_headline)\n",
        "        articles.append(_body)\n",
        "        labels.append(label_transform(_label))\n",
        "    # Transform labels to tensor and add padding to articles\n",
        "    labels = torch.tensor(labels)\n",
        "    headlines = pad_sequence(headlines)\n",
        "    articles = pad_sequence(articles)\n",
        "\n",
        "    pad = articles.shape[0] - headlines.shape[0]\n",
        "    headlines = F.pad(headlines, pad=(0,0, 0, pad), value=0)\n",
        "    # Transform labels to tensor and add padding to articles\n",
        "    return labels, headlines, articles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Tesis/Tesis/ISOTFakeNews/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOXc3K131fWy",
        "outputId": "6494d860-3105-46f5-848c-3c08a9c31b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean  test.csv  train.csv  valid.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKZehEqB1ijX",
        "outputId": "d40d5bbb-08f5-4836-ee22-c85615561472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQZhzh-hnJU3"
      },
      "outputs": [],
      "source": [
        "train_dataset = FakeNewsDataset(path=\"/content/drive/MyDrive/Tesis/Tesis/ISOTFakeNews/clean\", split=\"train\")\n",
        "valid_dataset = FakeNewsDataset(path=\"/content/drive/MyDrive/Tesis/Tesis/ISOTFakeNews/clean\", split=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJ1TM7exFj7",
        "outputId": "a2c4fe04-2ad6-46d1-cc02-4e3209ba51a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136788"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "vocab = build_vocab_from_corpus(train_dataset, tokenizer)\n",
        "vocab\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK120WUcAJxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9526e7d7-e056-4c81-ec93-2ce3f3b7af12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.39MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:56<00:00, 7129.20it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import GloVe\n",
        "vectors = GloVe(name='6B', dim=300)\n",
        "vocab = torch_vocab(vectors.stoi, specials=[\"BOH\", \"EOH\", \"BOP\", \"EOP\", \"<UNK>\"])\n",
        "vocab.set_default_index(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cTdmQtZMPlb"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(list(train_dataset), batch_size=32, shuffle=True,\n",
        "                                collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(list(valid_dataset), batch_size=32, shuffle=True,\n",
        "                                collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "model = LTSM_Encoder(input_dim=INPUT_DIM, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, num_layers=NUM_LAYERS, padding_idx=0, vectors=vectors.vectors)\n",
        "model_name = \"LTSMEncoderGloveISOTEXP2\"\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9cEGMZowZ4pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "run_experiment(\n",
        "    model=model, model_name=model_name,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    n_epochs=n_epochs,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d-79-TbaGnD",
        "outputId": "aaa02ec4-a3f1-4551-c060-e71b938e86d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finishing training epoch\n",
            "Epoch: 01 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.605 | Train f1: 0.63 | Train precision: 0.68 | Train recall: 0.66\n",
            "\t Val. Loss: 0.567 |  Val. f1: 0.70 |  Val. precision: 0.77 | Val. recall: 0.72\n",
            "Finishing training epoch\n",
            "Epoch: 02 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.227 | Train f1: 0.93 | Train precision: 0.94 | Train recall: 0.93\n",
            "\t Val. Loss: 0.062 |  Val. f1: 0.99 |  Val. precision: 0.99 | Val. recall: 0.99\n",
            "Finishing training epoch\n",
            "Epoch: 03 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.052 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.032 |  Val. f1: 0.99 |  Val. precision: 0.99 | Val. recall: 0.99\n",
            "Finishing training epoch\n",
            "Epoch: 04 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.029 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.017 |  Val. f1: 1.00 |  Val. precision: 1.00 | Val. recall: 1.00\n",
            "Finishing training epoch\n",
            "Epoch: 05 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.025 | Train f1: 1.00 | Train precision: 1.00 | Train recall: 1.00\n",
            "\t Val. Loss: 0.014 |  Val. f1: 1.00 |  Val. precision: 1.00 | Val. recall: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjApqHUF-2C1"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "model = BiDualEncoder(vocab_size=INPUT_DIM, embed_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, hidden_layers=NUM_LAYERS)\n",
        "model_name = \"BiDualEncoderISOTEXP3\"\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s_LicMU2r1p",
        "outputId": "a94532f8-f9ea-4dd1-d9e1-5e628ba6c46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finishing training epoch\n",
            "Epoch: 01 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.461 | Train f1: 0.79 | Train precision: 0.81 | Train recall: 0.80\n",
            "\t Val. Loss: 0.330 |  Val. f1: 0.89 |  Val. precision: 0.89 | Val. recall: 0.89\n",
            "Finishing training epoch\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.431 | Train f1: 0.80 | Train precision: 0.84 | Train recall: 0.81\n",
            "\t Val. Loss: 0.273 |  Val. f1: 0.91 |  Val. precision: 0.92 | Val. recall: 0.91\n",
            "Finishing training epoch\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.171 | Train f1: 0.94 | Train precision: 0.95 | Train recall: 0.95\n",
            "\t Val. Loss: 0.394 |  Val. f1: 0.81 |  Val. precision: 0.86 | Val. recall: 0.82\n",
            "Finishing training epoch\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.136 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.96\n",
            "\t Val. Loss: 0.188 |  Val. f1: 0.93 |  Val. precision: 0.94 | Val. recall: 0.93\n",
            "Finishing training epoch\n",
            "Epoch: 05 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.069 | Train f1: 0.98 | Train precision: 0.98 | Train recall: 0.98\n",
            "\t Val. Loss: 0.055 |  Val. f1: 0.98 |  Val. precision: 0.99 | Val. recall: 0.98\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "\n",
        "run_experiment(\n",
        "    model=model, model_name=model_name,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    n_epochs=n_epochs,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "model = BiDualEncoder(vocab_size=INPUT_DIM, embed_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, hidden_layers=NUM_LAYERS, vectors=vectors.vectors)\n",
        "model_name = \"BiDualEncoderGloveISOTEXP4\"\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "-bVwnzByaIBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "run_experiment(\n",
        "    model=model, model_name=model_name,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    n_epochs=n_epochs,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zrxL1VtaN6W",
        "outputId": "5fdebb5f-ff50-4c16-f16f-ea7762b725de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finishing training epoch\n",
            "Epoch: 01 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 0.655 | Train f1: 0.58 | Train precision: 0.62 | Train recall: 0.61\n",
            "\t Val. Loss: 0.694 |  Val. f1: 0.54 |  Val. precision: 0.60 | Val. recall: 0.58\n",
            "Finishing training epoch\n",
            "Epoch: 02 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 0.556 | Train f1: 0.70 | Train precision: 0.74 | Train recall: 0.72\n",
            "\t Val. Loss: 1.308 |  Val. f1: 0.34 |  Val. precision: 0.29 | Val. recall: 0.50\n",
            "Finishing training epoch\n",
            "Epoch: 03 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.478 | Train f1: 0.77 | Train precision: 0.78 | Train recall: 0.78\n",
            "\t Val. Loss: 0.211 |  Val. f1: 0.92 |  Val. precision: 0.93 | Val. recall: 0.93\n",
            "Finishing training epoch\n",
            "Epoch: 04 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.135 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.96\n",
            "\t Val. Loss: 0.042 |  Val. f1: 0.99 |  Val. precision: 0.99 | Val. recall: 0.99\n",
            "Finishing training epoch\n",
            "Epoch: 05 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.322 | Train f1: 0.81 | Train precision: 0.82 | Train recall: 0.82\n",
            "\t Val. Loss: 0.638 |  Val. f1: 0.68 |  Val. precision: 0.69 | Val. recall: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfmiFwAZGYXP"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "model = BiConditionalDualEncoder(vocab_size=INPUT_DIM, embed_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, hidden_layers=NUM_LAYERS)\n",
        "model_name = \"BiConditionalDualEncoderISOTEXP5\"\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IQdWDLn1fww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc286ad-b4f4-4f07-b346-c2a84130bdaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finishing training epoch\n",
            "Epoch: 01 | Epoch Time: 1m 23s\n",
            "\tTrain Loss: 0.180 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.93\n",
            "\t Val. Loss: 0.082 |  Val. f1: 0.97 |  Val. precision: 0.97 | Val. recall: 0.97\n",
            "Finishing training epoch\n",
            "Epoch: 02 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.040 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.065 |  Val. f1: 0.98 |  Val. precision: 0.98 | Val. recall: 0.98\n",
            "Finishing training epoch\n",
            "Epoch: 03 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.022 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.068 |  Val. f1: 0.98 |  Val. precision: 0.98 | Val. recall: 0.98\n",
            "Finishing training epoch\n",
            "Epoch: 04 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.005 | Train f1: 1.00 | Train precision: 1.00 | Train recall: 1.00\n",
            "\t Val. Loss: 0.070 |  Val. f1: 0.98 |  Val. precision: 0.98 | Val. recall: 0.98\n",
            "Finishing training epoch\n",
            "Epoch: 05 | Epoch Time: 1m 24s\n",
            "\tTrain Loss: 0.004 | Train f1: 1.00 | Train precision: 1.00 | Train recall: 1.00\n",
            "\t Val. Loss: 0.079 |  Val. f1: 0.98 |  Val. precision: 0.98 | Val. recall: 0.98\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "\n",
        "run_experiment(\n",
        "    model=model, model_name=model_name,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    n_epochs=n_epochs,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIUvhVtrAg0q"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "model = BiConditionalDualEncoder(vocab_size=INPUT_DIM, embed_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, hidden_layers=NUM_LAYERS, vectors=vectors.vectors)\n",
        "model_name = \"BiConditionalDualEncoderGloveISOTEXP6\"\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j-Ee59TEdrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786a67cb-ad93-4ba7-e830-3f5f6decef39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finishing training epoch\n",
            "Epoch: 01 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.225 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.90\n",
            "\t Val. Loss: 0.124 |  Val. f1: 0.95 |  Val. precision: 0.95 | Val. recall: 0.95\n",
            "Finishing training epoch\n",
            "Epoch: 02 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.105 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.96\n",
            "\t Val. Loss: 0.109 |  Val. f1: 0.96 |  Val. precision: 0.96 | Val. recall: 0.96\n",
            "Finishing training epoch\n",
            "Epoch: 03 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.065 | Train f1: 0.97 | Train precision: 0.98 | Train recall: 0.98\n",
            "\t Val. Loss: 0.103 |  Val. f1: 0.96 |  Val. precision: 0.96 | Val. recall: 0.96\n",
            "Finishing training epoch\n",
            "Epoch: 04 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 0.042 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.111 |  Val. f1: 0.97 |  Val. precision: 0.97 | Val. recall: 0.97\n",
            "Finishing training epoch\n",
            "Epoch: 05 | Epoch Time: 0m 52s\n",
            "\tTrain Loss: 0.031 | Train f1: 0.99 | Train precision: 0.99 | Train recall: 0.99\n",
            "\t Val. Loss: 0.095 |  Val. f1: 0.97 |  Val. precision: 0.97 | Val. recall: 0.97\n"
          ]
        }
      ],
      "source": [
        "run_experiment(\n",
        "    model=model, model_name=model_name,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_dataloader,\n",
        "    valid_dataloader=valid_dataloader,\n",
        "    n_epochs=n_epochs,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5_9A73vccAg"
      },
      "source": [
        "## Discard from here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_b8QktAqjCP"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZep5oFbqkyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64e5d11-9ee8-4163-eb07-27ba119cb7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers &> /dev/null\n",
        "!pip install sentencepiece &> /dev/null\n",
        "!pip install torchmetrics & > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oqfz69HrNgn"
      },
      "source": [
        "BERT comes with its own tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LU30KbWqq8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "07efa2fc5d2540f6bef0fd11ded9fbfa",
            "c46e77a5d5fd4192896a03cb51882b99",
            "eea0123b66484d248ef9952957e1d0eb",
            "23f64dd7168d4e64af41c79a2f9f1b15",
            "2506f0b8040f402bbad50e20c07616c7",
            "abebb2aba043440ab3476d5c8412ef09",
            "0b4e8109d27943d4bfa95d6222254d0f",
            "1888f3a8e04d4894b77a9332ad355206",
            "ea49c58fc8e845c497107e688f35891a",
            "d806224e05b14d90ab6d8a6d21c07238",
            "14feef33b7394e96af815e59871d1ee1",
            "b88f749efba64fb48c552e049f9dd050",
            "0c9511b472f54ce9a843ca27787ad3e5",
            "64d5a1f6079d43c4bdc58d496314b2d3",
            "358e7fc443754befb885c303d9224e5b",
            "4572b93a1f54412184d1edf88e69014f",
            "9278b580f84748e19aa338a7a60da70a",
            "06f52e9015b44709a28ac48842a1e2a9",
            "e9516c1ffd55455696cff9cf93082775",
            "b90a122ddd364ed4a685a6dcda8b31c3",
            "a91f471d81794f4f844447f668335751",
            "6c19b52b6f94401c9999f707b27c688c",
            "1e42317df4024d029acb54f7db6c29d9",
            "306edea2d2564e3ebfeebbc9e8d900ec",
            "c79d182f699c4d56a61c552841198207",
            "621db8ea818c476f81b2668b2a266d0e",
            "3d9fd49473ca4b52aa7be014223b494e",
            "888512a9ce1b4992a31d0b0743597dd4",
            "b27df8a6cb15498784f12617ba228e8c",
            "5d44a9721aab4c94a07fc51a309778a3",
            "a729b653b3b949a8aa2a30bc3a2a586f",
            "43d86280870e4b79ba3da818c32bf8de",
            "f08655ec2b7b4b92b35a3cbada58a7c6",
            "b767f92c714b482a874df43fbd33f5d0",
            "988ab0d968cb43ae8a733f791bdbd6ca",
            "162a41f4dacb4cb98c8376dfd5e5e600",
            "9df7a24f5d104f32ae603834fa5aa958",
            "81cc3ae6a9bc4381987d23f88fcfbc32",
            "be2f6434bc4d410c9b8d941fc3e131b9",
            "e1f2c8a13df34aedb16f6b3888a4b8fa",
            "e685daf7fca3495caeab9558eee4b9cd",
            "eb2ad55f068149ada0c802fe6a037646",
            "9075c3990a944cd382c0152a6f78d853",
            "7ab2954b61204a48862bed2943dc8d9a"
          ]
        },
        "outputId": "de9b48c3-406a-470c-e281-ad157d612bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07efa2fc5d2540f6bef0fd11ded9fbfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b88f749efba64fb48c552e049f9dd050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e42317df4024d029acb54f7db6c29d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b767f92c714b482a874df43fbd33f5d0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zntzSMVrTUd"
      },
      "source": [
        "We need to change our collate_batch function to adapt our data to BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qpWJtX0rIFC"
      },
      "outputs": [],
      "source": [
        "label_dict = {\n",
        "    'true': 0,\n",
        "    'fake': 1,\n",
        "}\n",
        "\n",
        "def collate_batch(batch):\n",
        "\n",
        "    token_ids, mask_ids, segment_ids, labels = [], [], [], []\n",
        "\n",
        "    for (_headline, _body, _label) in batch:\n",
        "        _headline_id = tokenizer.encode(_headline, add_special_tokens=False)[:512]\n",
        "        _headline_len = len(_headline_id)\n",
        "        _body_id = tokenizer.encode(_body[:(512 - _headline_len - 3)], add_special_tokens=False)\n",
        "        _pair_token_ids = [tokenizer.cls_token_id] + _body_id + [tokenizer.sep_token_id] + _headline_id + [tokenizer.sep_token_id]\n",
        "\n",
        "        _body_len = len(_body_id)\n",
        "\n",
        "        _segment_ids = torch.tensor([0] * (_body_len + 2) + [1] * (_headline_len + 1))\n",
        "        _attn_mask_ids = torch.tensor([1] * (_body_len + _headline_len + 3))\n",
        "\n",
        "        token_ids.append(torch.tensor(_pair_token_ids))\n",
        "        segment_ids.append(_segment_ids)\n",
        "        mask_ids.append(_attn_mask_ids)\n",
        "\n",
        "        labels.append(label_dict[_label])\n",
        "\n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    segment_ids = pad_sequence(segment_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return token_ids, mask_ids, segment_ids, labels\n",
        "\n",
        "train_dataloader = DataLoader(list(train_dataset), batch_size=32, shuffle=True,\n",
        "                                collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(list(valid_dataset), batch_size=32, shuffle=True,\n",
        "                                collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHThm0FyrkCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5201e211-10a0-4b03-868d-5bad927bb8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsegc678rnF5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from torchmetrics import F1Score\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "f1_score = F1Score(task=\"binary\", average='macro')\n",
        "f1_score = f1_score.to(device)\n",
        "\n",
        "def train_bert(model, train_loader, val_loader, optimizer, n_epochs):\n",
        "  total_step = len(train_loader)\n",
        "  BEST_F1 = 0\n",
        "  for epoch in range(n_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_acc  = 0\n",
        "    total_train_f1 = 0\n",
        "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      pair_token_ids = pair_token_ids.to(device)\n",
        "      mask_ids = mask_ids.to(device)\n",
        "      seg_ids = seg_ids.to(device)\n",
        "      labels = y.to(device)\n",
        "      loss, prediction = model(pair_token_ids,\n",
        "                             token_type_ids=seg_ids,\n",
        "                             attention_mask=mask_ids,\n",
        "                             labels=labels).values()\n",
        "\n",
        "      acc = multi_acc(prediction, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "      total_train_acc  += acc.item()\n",
        "      total_train_f1 += f1_score(torch.argmax(prediction, dim=1), labels)\n",
        "\n",
        "    train_acc  = total_train_acc/len(train_loader)\n",
        "    train_loss = total_train_loss/len(train_loader)\n",
        "    train_f1 = total_train_f1/len(train_loader)\n",
        "    model.eval()\n",
        "    total_val_acc  = 0\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      y_preds = torch.tensor(()).int().to(device)\n",
        "      y_tests = torch.tensor(()).int().to(device)\n",
        "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        pair_token_ids = pair_token_ids.to(device)\n",
        "        mask_ids = mask_ids.to(device)\n",
        "        seg_ids = seg_ids.to(device)\n",
        "        labels = y.to(device)\n",
        "\n",
        "        loss, prediction = model(pair_token_ids,\n",
        "                             token_type_ids=seg_ids,\n",
        "                             attention_mask=mask_ids,\n",
        "                             labels=labels).values()\n",
        "\n",
        "        y_pred = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
        "        y_preds = torch.cat([y_preds, y_pred])\n",
        "        y_tests = torch.cat([y_tests, labels])\n",
        "\n",
        "        total_val_loss += loss.item()\n",
        "        total_val_acc  += acc.item()\n",
        "\n",
        "    val_f1 = f1_score(y_preds, y_tests)\n",
        "    if val_f1 > BEST_F1:\n",
        "        BEST_F1 = val_f1\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/Tesis/bert-isort.pt')\n",
        "    val_acc  = total_val_acc/len(val_loader)\n",
        "    val_loss = total_val_loss/len(val_loader)\n",
        "    end = time.time()\n",
        "    hours, rem = divmod(end-start, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_f1: {train_f1:.4f} | val_loss: {val_loss:.4f} val_f1: {val_f1:.4f}')\n",
        "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAJod7qptAzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ba6ab3-03b0-4447-b863-1dadd4f1d616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss: 0.0150 train_f1: 0.9937 | val_loss: 0.0051 val_f1: 0.9989\n",
            "00:13:01.82\n",
            "Epoch 2: train_loss: 0.0023 train_f1: 0.9996 | val_loss: 0.0025 val_f1: 0.9995\n",
            "00:13:02.39\n",
            "Epoch 3: train_loss: 0.0004 train_f1: 0.9986 | val_loss: 0.0040 val_f1: 0.9994\n",
            "00:12:54.05\n"
          ]
        }
      ],
      "source": [
        "train_bert(model, train_dataloader, valid_dataloader, optimizer, 3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07efa2fc5d2540f6bef0fd11ded9fbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c46e77a5d5fd4192896a03cb51882b99",
              "IPY_MODEL_eea0123b66484d248ef9952957e1d0eb",
              "IPY_MODEL_23f64dd7168d4e64af41c79a2f9f1b15"
            ],
            "layout": "IPY_MODEL_2506f0b8040f402bbad50e20c07616c7"
          }
        },
        "c46e77a5d5fd4192896a03cb51882b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abebb2aba043440ab3476d5c8412ef09",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4e8109d27943d4bfa95d6222254d0f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "eea0123b66484d248ef9952957e1d0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1888f3a8e04d4894b77a9332ad355206",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea49c58fc8e845c497107e688f35891a",
            "value": 48
          }
        },
        "23f64dd7168d4e64af41c79a2f9f1b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d806224e05b14d90ab6d8a6d21c07238",
            "placeholder": "​",
            "style": "IPY_MODEL_14feef33b7394e96af815e59871d1ee1",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.30kB/s]"
          }
        },
        "2506f0b8040f402bbad50e20c07616c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abebb2aba043440ab3476d5c8412ef09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4e8109d27943d4bfa95d6222254d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1888f3a8e04d4894b77a9332ad355206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea49c58fc8e845c497107e688f35891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d806224e05b14d90ab6d8a6d21c07238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14feef33b7394e96af815e59871d1ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b88f749efba64fb48c552e049f9dd050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c9511b472f54ce9a843ca27787ad3e5",
              "IPY_MODEL_64d5a1f6079d43c4bdc58d496314b2d3",
              "IPY_MODEL_358e7fc443754befb885c303d9224e5b"
            ],
            "layout": "IPY_MODEL_4572b93a1f54412184d1edf88e69014f"
          }
        },
        "0c9511b472f54ce9a843ca27787ad3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9278b580f84748e19aa338a7a60da70a",
            "placeholder": "​",
            "style": "IPY_MODEL_06f52e9015b44709a28ac48842a1e2a9",
            "value": "vocab.txt: 100%"
          }
        },
        "64d5a1f6079d43c4bdc58d496314b2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9516c1ffd55455696cff9cf93082775",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b90a122ddd364ed4a685a6dcda8b31c3",
            "value": 231508
          }
        },
        "358e7fc443754befb885c303d9224e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91f471d81794f4f844447f668335751",
            "placeholder": "​",
            "style": "IPY_MODEL_6c19b52b6f94401c9999f707b27c688c",
            "value": " 232k/232k [00:00&lt;00:00, 2.71MB/s]"
          }
        },
        "4572b93a1f54412184d1edf88e69014f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9278b580f84748e19aa338a7a60da70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f52e9015b44709a28ac48842a1e2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9516c1ffd55455696cff9cf93082775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90a122ddd364ed4a685a6dcda8b31c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91f471d81794f4f844447f668335751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c19b52b6f94401c9999f707b27c688c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e42317df4024d029acb54f7db6c29d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306edea2d2564e3ebfeebbc9e8d900ec",
              "IPY_MODEL_c79d182f699c4d56a61c552841198207",
              "IPY_MODEL_621db8ea818c476f81b2668b2a266d0e"
            ],
            "layout": "IPY_MODEL_3d9fd49473ca4b52aa7be014223b494e"
          }
        },
        "306edea2d2564e3ebfeebbc9e8d900ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888512a9ce1b4992a31d0b0743597dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_b27df8a6cb15498784f12617ba228e8c",
            "value": "tokenizer.json: 100%"
          }
        },
        "c79d182f699c4d56a61c552841198207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d44a9721aab4c94a07fc51a309778a3",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a729b653b3b949a8aa2a30bc3a2a586f",
            "value": 466062
          }
        },
        "621db8ea818c476f81b2668b2a266d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d86280870e4b79ba3da818c32bf8de",
            "placeholder": "​",
            "style": "IPY_MODEL_f08655ec2b7b4b92b35a3cbada58a7c6",
            "value": " 466k/466k [00:00&lt;00:00, 7.22MB/s]"
          }
        },
        "3d9fd49473ca4b52aa7be014223b494e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888512a9ce1b4992a31d0b0743597dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27df8a6cb15498784f12617ba228e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d44a9721aab4c94a07fc51a309778a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a729b653b3b949a8aa2a30bc3a2a586f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43d86280870e4b79ba3da818c32bf8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08655ec2b7b4b92b35a3cbada58a7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b767f92c714b482a874df43fbd33f5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988ab0d968cb43ae8a733f791bdbd6ca",
              "IPY_MODEL_162a41f4dacb4cb98c8376dfd5e5e600",
              "IPY_MODEL_9df7a24f5d104f32ae603834fa5aa958"
            ],
            "layout": "IPY_MODEL_81cc3ae6a9bc4381987d23f88fcfbc32"
          }
        },
        "988ab0d968cb43ae8a733f791bdbd6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2f6434bc4d410c9b8d941fc3e131b9",
            "placeholder": "​",
            "style": "IPY_MODEL_e1f2c8a13df34aedb16f6b3888a4b8fa",
            "value": "config.json: 100%"
          }
        },
        "162a41f4dacb4cb98c8376dfd5e5e600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e685daf7fca3495caeab9558eee4b9cd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb2ad55f068149ada0c802fe6a037646",
            "value": 570
          }
        },
        "9df7a24f5d104f32ae603834fa5aa958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9075c3990a944cd382c0152a6f78d853",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab2954b61204a48862bed2943dc8d9a",
            "value": " 570/570 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "81cc3ae6a9bc4381987d23f88fcfbc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2f6434bc4d410c9b8d941fc3e131b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f2c8a13df34aedb16f6b3888a4b8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e685daf7fca3495caeab9558eee4b9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2ad55f068149ada0c802fe6a037646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9075c3990a944cd382c0152a6f78d853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab2954b61204a48862bed2943dc8d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}